{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Blnye0uhS817"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHIp7YF6Sxh9"
      },
      "source": [
        "# CIS468 Project Report - Auto Tagger Todo-List DB Version 2\n",
        "\n",
        "project/\n",
        "\n",
        "todos:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BB8ycqOYIJG"
      },
      "source": [
        "## Initialize the Envrionment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6vIl2M6YHoK",
        "outputId": "2fce9c5a-bd00-4fc1-dc48-e938f51af6c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.8.3)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement sqlite3 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for sqlite3\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# install the spaCy model\n",
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_lg\n",
        "!pip install sqlite3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vw_JTOSdP-p"
      },
      "source": [
        "## Corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGe1_NDodR_T"
      },
      "outputs": [],
      "source": [
        "# Not Used, Generated by ChatGPT.\n",
        "\n",
        "corpus = [\n",
        "    # ===== Sports =====\n",
        "    (\"Play basketball with Alex at Central Park tomorrow 3pm\", \"sports\"),\n",
        "    (\"Join soccer practice at 5:30pm this Friday\", \"sports\"),\n",
        "    (\"Morning run around the lake at 6am\", \"sports\"),\n",
        "    (\"Tennis match with Sarah next Saturday afternoon\", \"sports\"),\n",
        "    (\"Sign up for yoga class this evening\", \"sports\"),\n",
        "    (\"Watch Lakers game with Mike tonight at 8\", \"sports\"),\n",
        "    (\"Buy new running shoes before next week's marathon\", \"sports\"),\n",
        "    (\"Hiking trip with family this weekend\", \"sports\"),\n",
        "    (\"Swim practice at community center tomorrow morning\", \"sports\"),\n",
        "    (\"Organize basketball tournament for team next month\", \"sports\"),\n",
        "\n",
        "    # ===== Cooking =====\n",
        "    (\"Cook dinner for family tonight\", \"cooking\"),\n",
        "    (\"Try new pasta recipe tomorrow evening\", \"cooking\"),\n",
        "    (\"Bake birthday cake for mom this Saturday\", \"cooking\"),\n",
        "    (\"Prepare lunch for office potluck next Friday\", \"cooking\"),\n",
        "    (\"Make vegetarian lasagna for dinner party\", \"cooking\"),\n",
        "    (\"Experiment with sushi making this weekend\", \"cooking\"),\n",
        "    (\"Grill steaks for backyard BBQ on Sunday\", \"cooking\"),\n",
        "    (\"Learn to make French toast tomorrow morning\", \"cooking\"),\n",
        "    (\"Cook Thanksgiving turkey next Thursday\", \"cooking\"),\n",
        "    (\"Prepare meal prep for next week on Sunday\", \"cooking\"),\n",
        "\n",
        "    # ===== Gaming =====\n",
        "    (\"Play Call of Duty with friends tonight at 9pm\", \"gaming\"),\n",
        "    (\"Join Minecraft server this weekend\", \"gaming\"),\n",
        "    (\"Finish Zelda: Tears of the Kingdom by next week\", \"gaming\"),\n",
        "    (\"Online chess tournament Saturday afternoon\", \"gaming\"),\n",
        "    (\"Stream Fortnite gameplay tomorrow evening\", \"gaming\"),\n",
        "    (\"Buy new gaming headset before next month\", \"gaming\"),\n",
        "    (\"LAN party at Mark's place this Friday\", \"gaming\"),\n",
        "    (\"Practice for esports competition next month\", \"gaming\"),\n",
        "    (\"Update gaming PC components this weekend\", \"gaming\"),\n",
        "    (\"Try new VR game with Alex tomorrow\", \"gaming\"),\n",
        "\n",
        "    # ===== Work =====\n",
        "    (\"Finish quarterly report by next Friday\", \"work\"),\n",
        "    (\"Prepare presentation for Monday meeting\", \"work\"),\n",
        "    (\"Conference call with Tokyo team at 9am tomorrow\", \"work\"),\n",
        "    (\"Submit expense reports before end of month\", \"work\"),\n",
        "    (\"Interview candidates for developer position\", \"work\"),\n",
        "    (\"Review project timeline with team this afternoon\", \"work\"),\n",
        "    (\"Attend leadership workshop next Wednesday\", \"work\"),\n",
        "    (\"Complete budget planning by end of week\", \"work\"),\n",
        "    (\"Organize team building event next month\", \"work\"),\n",
        "    (\"Update company website content tomorrow\", \"work\"),\n",
        "\n",
        "    # ===== Study =====\n",
        "    (\"Study for calculus exam next Monday\", \"study\"),\n",
        "    (\"Complete CIS468 project by next Friday\", \"study\"),\n",
        "    (\"Research paper on machine learning due next month\", \"study\"),\n",
        "    (\"Group study session at library tomorrow 2pm\", \"study\"),\n",
        "    (\"Prepare for TOEFL test this weekend\", \"study\"),\n",
        "    (\"Watch lecture videos on quantum computing\", \"study\"),\n",
        "    (\"Read chapters 5-7 for literature class\", \"study\"),\n",
        "    (\"Practice Python coding exercises tonight\", \"study\"),\n",
        "    (\"Attend machine learning workshop next week\", \"study\"),\n",
        "    (\"Review Spanish vocabulary before class tomorrow\", \"study\"),\n",
        "\n",
        "    # ===== Shopping =====\n",
        "    (\"Buy groceries at Whole Foods tomorrow\", \"shopping\"),\n",
        "    (\"Get birthday gift for mom this weekend\", \"shopping\"),\n",
        "    (\"Purchase new laptop before next semester\", \"shopping\"),\n",
        "    (\"Clothes shopping at mall next Saturday\", \"shopping\"),\n",
        "    (\"Order kitchen supplies online tonight\", \"shopping\"),\n",
        "    (\"Look for new sofa this weekend\", \"shopping\"),\n",
        "    (\"Get ingredients for dinner party tomorrow\", \"shopping\"),\n",
        "    (\"Christmas gift shopping next month\", \"shopping\"),\n",
        "    (\"Buy new phone case before trip\", \"shopping\"),\n",
        "    (\"Grocery delivery for next week\", \"shopping\")\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataBase"
      ],
      "metadata": {
        "id": "VMnBVSTXg3RL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import json\n",
        "\n",
        "class DatabaseManager:\n",
        "    def __init__(self, db_path='/content/drive/MyDrive/todo_records.db'):\n",
        "        \"\"\"Initialize database connection\"\"\"\n",
        "        self.db_path = db_path\n",
        "        self._create_table()\n",
        "\n",
        "    def _create_table(self):\n",
        "        \"\"\"Create database table if not exists\"\"\"\n",
        "        with sqlite3.connect(self.db_path) as conn:\n",
        "            c = conn.cursor()\n",
        "            c.execute('''\n",
        "                CREATE TABLE IF NOT EXISTS todo_records (\n",
        "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                    original_text TEXT NOT NULL,\n",
        "                    creation_time TEXT NOT NULL,\n",
        "                    candidate_labels TEXT NOT NULL,\n",
        "                    predicted_tags TEXT NOT NULL,\n",
        "                    ner_results TEXT NOT NULL\n",
        "                )\n",
        "            ''')\n",
        "            conn.commit()\n",
        "\n",
        "    def save_record(self, record):\n",
        "        \"\"\"Save record to database\"\"\"\n",
        "        with sqlite3.connect(self.db_path) as conn:\n",
        "            c = conn.cursor()\n",
        "            c.execute('''\n",
        "                INSERT INTO todo_records (\n",
        "                    original_text,\n",
        "                    creation_time,\n",
        "                    candidate_labels,\n",
        "                    predicted_tags,\n",
        "                    ner_results\n",
        "                ) VALUES (?, ?, ?, ?, ?)\n",
        "            ''', (\n",
        "                record[\"original_text\"],\n",
        "                record[\"creation_time\"],\n",
        "                json.dumps(record[\"candidate_labels\"]),\n",
        "                json.dumps(record[\"predicted_tags\"]),\n",
        "                json.dumps(record[\"ner_results\"])\n",
        "            ))\n",
        "            conn.commit()\n",
        "            return c.lastrowid\n",
        "\n",
        "    def load_records(self):\n",
        "        \"\"\"Load all records from database\"\"\"\n",
        "        with sqlite3.connect(self.db_path) as conn:\n",
        "            c = conn.cursor()\n",
        "            c.execute(\"SELECT * FROM todo_records\")\n",
        "            records = []\n",
        "            for row in c.fetchall():\n",
        "                records.append({\n",
        "                    \"id\": row[0],\n",
        "                    \"original_text\": row[1],\n",
        "                    \"creation_time\": row[2],\n",
        "                    \"candidate_labels\": json.loads(row[3]),\n",
        "                    \"predicted_tags\": json.loads(row[4]),\n",
        "                    \"ner_results\": json.loads(row[5])\n",
        "                })\n",
        "            return records\n"
      ],
      "metadata": {
        "id": "Lda951WonYnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DZTVHdaiB1E"
      },
      "source": [
        "## NER Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iuy0ZAHYloMg",
        "outputId": "15e8916c-1b9a-4192-8654-f5770ee2e4c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dateparser\n",
            "  Downloading dateparser-1.2.2-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2025.2)\n",
            "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.11/dist-packages (from dateparser) (2024.11.6)\n",
            "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.11/dist-packages (from dateparser) (5.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7.0->dateparser) (1.17.0)\n",
            "Downloading dateparser-1.2.2-py3-none-any.whl (315 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/315.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dateparser\n",
            "Successfully installed dateparser-1.2.2\n"
          ]
        }
      ],
      "source": [
        "# Initialize the Environment\n",
        "!pip install dateparser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiCN3RHUTECe"
      },
      "source": [
        "### ner_extractor.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ3m5idSRmVj",
        "outputId": "fd150407-ad67-4ea4-d03e-7454ee6bacf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model: en_core_web_lg\n",
            "{'original_text': 'Meet John at Google HQ tomorrow at 3pm for product launch', 'event_time': '2025-08-10 03:12', 'persons': ['Meet John']}\n"
          ]
        }
      ],
      "source": [
        "# ner_extractor.py\n",
        "\n",
        "'''\n",
        "todo: complete todos in _extract_and_parse_time\n",
        "'''\n",
        "\n",
        "import datetime\n",
        "import spacy\n",
        "import dateparser\n",
        "\n",
        "class EnhancedNERExtractor:\n",
        "    def __init__(self, model_path=\"en_core_web_lg\"):\n",
        "        \"\"\"\n",
        "        Initialize the NER extractor\n",
        "        :param model_path: spaCy model path or name\n",
        "        \"\"\"\n",
        "        self.nlp = spacy.load(model_path)\n",
        "        print(f\"Loaded model: {model_path}\")\n",
        "\n",
        "    def extract_entities(self, text, current_time=None, output_format=\"%Y-%m-%d %H:%M\"):\n",
        "        \"\"\"\n",
        "        Enhanced NER extraction\n",
        "        :param text: Input text\n",
        "        :param current_time: Current time (datetime object)\n",
        "        :param output_format: Time output format\n",
        "        :return: Dictionary containing entity information\n",
        "        \"\"\"\n",
        "        doc = self.nlp(text)\n",
        "\n",
        "        # Extract basic entities\n",
        "        entities = {\n",
        "            \"original_text\": text,\n",
        "            \"event_time\": self._extract_and_parse_time(doc, current_time, output_format),\n",
        "            \"persons\": self._extract_persons(doc),\n",
        "\n",
        "            # Todo: Continue to extract more identities\n",
        "            # \"organizations\": self._extract_organizations(doc),\n",
        "            # \"events\": self._extract_events(doc),\n",
        "            # \"other_nouns\": self._extract_other_nouns(doc)\n",
        "        }\n",
        "\n",
        "        return entities\n",
        "\n",
        "\n",
        "    def _extract_and_parse_time(self, doc, current_time, output_format):\n",
        "        '''\n",
        "        todo: add duration field to the modification the time model, to save duration of the event\n",
        "        todo: Failed to recognize, and consider all of the time expressions\n",
        "          {'original_text': 'Meet John at Google HQ tomorrow from 3pm to 5pm for product launch', 'event_time': '2023-10-16 14:30', 'persons': ['Meet John'], 'organizations': [], 'events': [], 'other_nouns': ['product', 'launch']}\n",
        "        todo: Better logic of the time recognition is required\n",
        "          {'original_text': 'I need to double check TA with my final before the end of today', 'event_time': None, 'persons': [], 'organizations': [], 'events': [], 'other_nouns': ['end', 'today']}\n",
        "        '''\n",
        "        time_exprs = []\n",
        "        # Combine continuous time words (e.g., \"next Monday at 3pm\")\n",
        "        for ent in doc.ents:\n",
        "            if ent.label_ in [\"DATE\", \"TIME\"]:\n",
        "                # Check if the words are adjacent\n",
        "                if time_exprs and ent.start == time_exprs[-1][\"end\"]:\n",
        "                    time_exprs[-1][\"text\"] += \" \" + ent.text\n",
        "                    time_exprs[-1][\"end\"] = ent.end\n",
        "                else:\n",
        "                    time_exprs.append({\n",
        "                        \"text\": ent.text,\n",
        "                        \"start\": ent.start,\n",
        "                        \"end\": ent.end\n",
        "                    })\n",
        "\n",
        "        if not time_exprs:\n",
        "            return None\n",
        "\n",
        "        # Return the processed time\n",
        "        for expr in time_exprs:\n",
        "            parsed_time = dateparser.parse(\n",
        "                expr[\"text\"],\n",
        "                settings={'RELATIVE_BASE': current_time}\n",
        "            )\n",
        "            if parsed_time:\n",
        "                return parsed_time.strftime(output_format)\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _extract_persons(self, doc):\n",
        "        \"\"\"Extract person entities\"\"\"\n",
        "        return [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
        "\n",
        "    def _extract_organizations(self, doc):\n",
        "        \"\"\"Extract organization entities\"\"\"\n",
        "        return [ent.text for ent in doc.ents if ent.label_ in [\"ORG\", \"FAC\"]]\n",
        "\n",
        "    def _extract_events(self, doc):\n",
        "        \"\"\"Extract event entities\"\"\"\n",
        "        return [ent.text for ent in doc.ents if ent.label_ == \"EVENT\"]\n",
        "\n",
        "    def _extract_other_nouns(self, doc):\n",
        "        \"\"\"Extract other important nouns (non-entities)\"\"\"\n",
        "        return [token.text for token in doc if token.pos_ == \"NOUN\" and not token.ent_type_]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  # --- Sample ---\n",
        "\n",
        "  # Initialize extractor\n",
        "  extractor = EnhancedNERExtractor()\n",
        "\n",
        "  # Current time (example)\n",
        "  current_time = datetime.datetime.now()\n",
        "\n",
        "  # Example text\n",
        "  text = \"Meet John at Google HQ tomorrow at 3pm for product launch\"\n",
        "  # text = \"Meet John at Google HQ tomorrow from 3pm to 5pm for product launch\"\n",
        "  # text = \"I need to double check my final project with Prof.Gabriel before the end of today\"\n",
        "\n",
        "  # Execute extraction\n",
        "  result = extractor.extract_entities(\n",
        "      text=text,\n",
        "      current_time=current_time,\n",
        "      output_format=\"%Y-%m-%d %H:%M\"\n",
        "  )\n",
        "  # Output result\n",
        "  print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5sb4fjhhtfq"
      },
      "source": [
        "### ner_identities_trainer.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TzWr_14Oz9LO"
      },
      "outputs": [],
      "source": [
        "# ner_trainer\n",
        "'''\n",
        "todo: train time\n",
        "todo: train rest of the entities\n",
        "'''\n",
        "class NERModelTrainer:\n",
        "    def __init__(self, base_model=\"en_core_web_lg\"):\n",
        "        \"\"\"\n",
        "        Initialize the model trainer\n",
        "        :param base_model: Base model name or path\n",
        "        \"\"\"\n",
        "        self.nlp = spacy.load(base_model)\n",
        "        print(f\"Initialized trainer with base model: {base_model}\")\n",
        "\n",
        "    def train_model(self, train_data, output_dir=\"custom_ner_model\", n_iter=20):\n",
        "        \"\"\"\n",
        "        Train a custom NER model\n",
        "        :param train_data: Training data list [(text, {\"entities\": [(start, end, label)]})]\n",
        "        :param output_dir: Model output directory\n",
        "        :param n_iter: Number of training iterations\n",
        "        :return: Path to the trained model\n",
        "        \"\"\"\n",
        "        # Add new entity labels (if they don't exist)\n",
        "        pass\n",
        "\n",
        "    @staticmethod\n",
        "    def prepare_training_data(corpus):\n",
        "        \"\"\"\n",
        "        Prepare training data (sample method, needs implementation based on actual corpus)\n",
        "        :param corpus: Raw corpus\n",
        "        :return: Formatted training data\n",
        "        \"\"\"\n",
        "        pass\n",
        "        # return training_data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmvmmmHEf_21"
      },
      "source": [
        "## Tag Allocation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgqJnHXJlM8g"
      },
      "source": [
        "### text_tager.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mIyF7EEf_22"
      },
      "outputs": [],
      "source": [
        "# Tager\n",
        "\n",
        "from transformers import pipeline\n",
        "from typing import List, Dict\n",
        "\n",
        "class EventTagger:\n",
        "    def __init__(self, model_name: str = \"facebook/bart-large-mnli\"):\n",
        "        \"\"\"\n",
        "        Initialize the zero-shot text classification model\n",
        "        :param model_name: Pretrained model (default: optimal for zero-shot classification)\n",
        "        \"\"\"\n",
        "        self.classifier = pipeline(\n",
        "            \"zero-shot-classification\",\n",
        "            model=model_name,\n",
        "            device=-1  # -1 for CPU, 0+ for GPU index\n",
        "        )\n",
        "\n",
        "    def predict_tags(\n",
        "        self,\n",
        "        text: str,\n",
        "        candidate_labels: List[str],\n",
        "        multi_label: bool = True,\n",
        "        threshold: float = 0.5\n",
        "    ) -> List[str]:\n",
        "        \"\"\"\n",
        "        Predict relevant tags for the event description\n",
        "        :param text: Event description text\n",
        "        :param candidate_labels: Set of candidate tags\n",
        "        :param multi_label: Allow multiple tags (default True)\n",
        "        :param threshold: Confidence threshold for tags (default 0.5)\n",
        "        :return: List of predicted tags\n",
        "        \"\"\"\n",
        "        results = self.classifier(\n",
        "            text,\n",
        "            candidate_labels,\n",
        "            multi_label=multi_label\n",
        "        )\n",
        "        return [\n",
        "            label for label, score in zip(results['labels'], results['scores'])\n",
        "            if score >= threshold\n",
        "        ]\n",
        "\n",
        "def tag_event(\n",
        "    text: str,\n",
        "    candidate_labels: List[str] = [\"sports\", \"cooking\", \"gaming\", \"work\", \"study\", \"shopping\"]\n",
        ") -> Dict[str, any]:\n",
        "    \"\"\"\n",
        "    Main workflow: Tag event descriptions\n",
        "    :param text: Event description text\n",
        "    :param candidate_labels: Set of candidate tags\n",
        "    :return: Dictionary with original input and predicted tags\n",
        "    \"\"\"\n",
        "    # Initialize tagger (singleton pattern to avoid reloading model)\n",
        "    if not hasattr(tag_event, 'tagger'):\n",
        "        tag_event.tagger = EventTagger()\n",
        "\n",
        "    # Predict tags\n",
        "    predicted_tags = tag_event.tagger.predict_tags(text, candidate_labels)\n",
        "\n",
        "    return {\n",
        "        \"original_text\": text,\n",
        "        \"candidate_labels\": candidate_labels,\n",
        "        \"predicted_tags\": predicted_tags\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Sample event descriptions\n",
        "    events = [\n",
        "        \"Need to buy groceries and kitchen supplies at the supermarket tomorrow\",\n",
        "        \"Team meeting this afternoon to discuss project requirements and prepare presentation\",\n",
        "        \"Playing badminton with friends at the sports center tonight\",\n",
        "        \"Researching machine learning algorithms for my thesis project\",\n",
        "        \"Cooking a three-course meal for family dinner this weekend\"\n",
        "    ]\n",
        "\n",
        "    # Execute tagging workflow\n",
        "    for event in events:\n",
        "        result = tag_event(event)\n",
        "        print(f\"Input text: {result['original_text']}\")\n",
        "        print(f\"Candidate labels: {result['candidate_labels']}\")\n",
        "        print(f\"Predicted tags: {result['predicted_tags']}\\n{'-'*50}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmVWLrGnlT57"
      },
      "source": [
        "### tagger_trainer.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_nks7jXAq1X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44WHR4qZvTxD"
      },
      "source": [
        "## Main Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "M423-GhOvamG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b2416bd-7194-4147-ce16-cb830a9d8f19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "Loaded model: en_core_web_lg\n",
            "\n",
            "=== Auto-Tagging Todo System ===\n",
            "1. Add new todo item\n",
            "2. View history\n",
            "3. Exit system\n",
            "Please select an option: 1\n",
            "\n",
            "=== 2025-08-08 23:06:48 EDT-0400 ===\n",
            "\n",
            "\n",
            "--- Step 1: Enter Todo Description ---\n",
            "Please describe what you plan to do: I plan to go play with my younger brother Bob\n",
            "\n",
            "=== 2025-08-08 23:07:30 EDT-0400 ===\n",
            "\n",
            "\n",
            "--- Step 2: Confirm Description ---\n",
            "Your input: I plan to go play with my younger brother Bob\n",
            "Is this description correct? (y/n): y\n",
            "\n",
            "=== 2025-08-08 23:07:34 EDT-0400 ===\n",
            "\n",
            "\n",
            "--- Step 3: Auto Analysis ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Named Entity Recognition Results ---\n",
            "Event Time: Not detected\n",
            "Persons: Bob\n",
            "\n",
            "--- Tag Classification Results ---\n",
            "Supported tags: sports, cooking, gaming, work, study, shopping\n",
            "Predicted tags: sports, gaming\n",
            "\n",
            "--- Step 4: Confirm Results ---\n",
            "Are the results correct? (y-correct/n-revise/c-cancel): y\n",
            "\n",
            "=== 2025-08-08 23:08:07 EDT-0400 ===\n",
            "\n",
            "\n",
            "--- Processing Complete ---\n",
            "Todo item saved successfully! Record ID: 1\n",
            "Content: I plan to go play with my younger brother Bob\n",
            "Time: 2025-08-08 23:08:07 EDT-0400\n",
            "Tags: sports, gaming\n",
            "\n",
            "=== 2025-08-08 23:08:07 EDT-0400 ===\n",
            "\n",
            "\n",
            "=== Auto-Tagging Todo System ===\n",
            "1. Add new todo item\n",
            "2. View history\n",
            "3. Exit system\n",
            "Please select an option: 2\n",
            "\n",
            "=== 2025-08-08 23:08:10 EDT-0400 ===\n",
            "\n",
            "\n",
            "Found 1 historical records:\n",
            "\n",
            "ID: 1\n",
            "Creation Time: 2025-08-08 23:08:07 EDT-0400\n",
            "Content: I plan to go play with my younger brother Bob\n",
            "Predicted Tags: sports, gaming\n",
            "Persons: Bob\n",
            "\n",
            "=== 2025-08-08 23:08:10 EDT-0400 ===\n",
            "\n",
            "\n",
            "=== Auto-Tagging Todo System ===\n",
            "1. Add new todo item\n",
            "2. View history\n",
            "3. Exit system\n",
            "Please select an option: 3\n",
            "\n",
            "=== 2025-08-08 23:09:03 EDT-0400 ===\n",
            "\n",
            "Thank you for using our system. Goodbye!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pytz\n",
        "\n",
        "class TodoApp:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize todo application\"\"\"\n",
        "        # Mount Google Drive for persistent storage\n",
        "        drive.mount('/content/drive/')\n",
        "\n",
        "        # Initialize database\n",
        "        self.db = DatabaseManager()\n",
        "\n",
        "        # Initialize NER extractor\n",
        "        self.ner_extractor = EnhancedNERExtractor()\n",
        "\n",
        "        # System supported tags\n",
        "        self.supported_tags = [\"sports\", \"cooking\", \"gaming\", \"work\", \"study\", \"shopping\"]\n",
        "\n",
        "    def get_formatted_datetime(self):\n",
        "        \"\"\"Get current time in New York timezone\"\"\"\n",
        "        ny_tz = pytz.timezone('America/New_York')\n",
        "        now = datetime.datetime.now(ny_tz)\n",
        "        return now.strftime(\"%Y-%m-%d %H:%M:%S %Z%z\")\n",
        "\n",
        "    def print_separator(self):\n",
        "        \"\"\"Print timestamped separator\"\"\"\n",
        "        separator = f\"=== {self.get_formatted_datetime()} ===\"\n",
        "        print(\"\\n\" + separator + \"\\n\")\n",
        "\n",
        "    def tag_event(self, text):\n",
        "        \"\"\"Tag classification workflow\"\"\"\n",
        "        # Initialize tagger on first use\n",
        "        if not hasattr(self, 'tagger'):\n",
        "            self.tagger = EventTagger()\n",
        "\n",
        "        return {\n",
        "            \"original_text\": text,\n",
        "            \"candidate_labels\": self.supported_tags,\n",
        "            \"predicted_tags\": self.tagger.predict_tags(text, self.supported_tags)\n",
        "        }\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Main application loop\"\"\"\n",
        "        while True:\n",
        "            # Main menu\n",
        "            print(\"\\n=== Auto-Tagging Todo System ===\")\n",
        "            print(\"1. Add new todo item\")\n",
        "            print(\"2. View history\")\n",
        "            print(\"3. Exit system\")\n",
        "            choice = input(\"Please select an option: \").strip()\n",
        "            self.print_separator()\n",
        "\n",
        "            if choice == \"3\":\n",
        "                print(\"Thank you for using our system. Goodbye!\")\n",
        "                break\n",
        "\n",
        "            elif choice == \"2\":\n",
        "                self.show_history()\n",
        "\n",
        "            elif choice == \"1\":\n",
        "                self.add_todo_item()\n",
        "\n",
        "            else:\n",
        "                print(\"Invalid selection, please try again\")\n",
        "\n",
        "    def add_todo_item(self):\n",
        "        \"\"\"Add new todo item workflow\"\"\"\n",
        "        # Step 1: Get todo description\n",
        "        print(\"\\n--- Step 1: Enter Todo Description ---\")\n",
        "        text = input(\"Please describe what you plan to do: \").strip()\n",
        "        self.print_separator()\n",
        "\n",
        "        # Step 2: Confirm description\n",
        "        print(\"\\n--- Step 2: Confirm Description ---\")\n",
        "        print(f\"Your input: {text}\")\n",
        "        confirm = input(\"Is this description correct? (y/n): \").lower().strip()\n",
        "        self.print_separator()\n",
        "\n",
        "        if confirm != \"y\":\n",
        "            print(\"Please re-enter the description\")\n",
        "            return\n",
        "\n",
        "        # Step 3: Automatic analysis\n",
        "        print(\"\\n--- Step 3: Auto Analysis ---\")\n",
        "\n",
        "        # Get current time in New York timezone\n",
        "        ny_tz = pytz.timezone('America/New_York')\n",
        "        current_time = datetime.datetime.now(ny_tz)\n",
        "\n",
        "        # Perform NER extraction\n",
        "        ner_result = self.ner_extractor.extract_entities(\n",
        "            text=text,\n",
        "            current_time=current_time,\n",
        "            output_format=\"%Y-%m-%d %H:%M\"\n",
        "        )\n",
        "\n",
        "        # Perform tag classification\n",
        "        tagging_result = self.tag_event(text)\n",
        "        predicted_tags = tagging_result[\"predicted_tags\"]\n",
        "\n",
        "        # Display NER results\n",
        "        print(\"\\n--- Named Entity Recognition Results ---\")\n",
        "        print(f\"Event Time: {ner_result['event_time'] or 'Not detected'}\")\n",
        "        print(f\"Persons: {', '.join(ner_result['persons']) or 'Not detected'}\")\n",
        "\n",
        "        # Display tag classification results\n",
        "        print(\"\\n--- Tag Classification Results ---\")\n",
        "        print(f\"Supported tags: {', '.join(self.supported_tags)}\")\n",
        "        print(f\"Predicted tags: {', '.join(predicted_tags) if predicted_tags else 'No tags predicted'}\")\n",
        "\n",
        "        # Step 4: Confirm results\n",
        "        print(\"\\n--- Step 4: Confirm Results ---\")\n",
        "        confirm_results = input(\"Are the results correct? (y-correct/n-revise/c-cancel): \").lower().strip()\n",
        "        self.print_separator()\n",
        "\n",
        "        if confirm_results == \"c\":\n",
        "            print(\"Operation cancelled\")\n",
        "            return\n",
        "\n",
        "        # Step 5: Manual tag selection if needed\n",
        "        if confirm_results == \"n\":\n",
        "            print(\"\\n--- Step 5: Manual Tag Selection ---\")\n",
        "            print(\"Please select tags (enter numbers separated by commas):\")\n",
        "            for i, tag in enumerate(self.supported_tags, 1):\n",
        "                print(f\"{i}. {tag}\")\n",
        "\n",
        "            while True:\n",
        "                tag_input = input(\"\\nEnter tag numbers: \").strip()\n",
        "                selected_indices = [s.strip() for s in tag_input.split(\",\") if s.strip()]\n",
        "\n",
        "                # Validate input\n",
        "                valid = True\n",
        "                selected_tags = []\n",
        "\n",
        "                for idx in selected_indices:\n",
        "                    if not idx.isdigit():\n",
        "                        print(f\"Error: '{idx}' is not a valid number\")\n",
        "                        valid = False\n",
        "                        break\n",
        "\n",
        "                    num = int(idx)\n",
        "                    if num < 1 or num > len(self.supported_tags):\n",
        "                        print(f\"Error: Number {num} is out of range (1-{len(self.supported_tags)})\")\n",
        "                        valid = False\n",
        "                        break\n",
        "\n",
        "                    selected_tags.append(self.supported_tags[num-1])\n",
        "\n",
        "                if not valid:\n",
        "                    continue\n",
        "\n",
        "                # Confirm selection\n",
        "                print(\"\\nSelected tags:\", \", \".join(selected_tags))\n",
        "                final_confirm = input(\"Confirm these tags? (y/n): \").lower().strip()\n",
        "\n",
        "                if final_confirm == \"y\":\n",
        "                    predicted_tags = selected_tags\n",
        "                    break\n",
        "\n",
        "        # Step 6: Save results to database\n",
        "        if confirm_results in (\"y\", \"n\"):\n",
        "            creation_time = self.get_formatted_datetime()\n",
        "\n",
        "            # Prepare record in required format\n",
        "            record = {\n",
        "                \"original_text\": text,\n",
        "                \"creation_time\": creation_time,\n",
        "                \"candidate_labels\": self.supported_tags,\n",
        "                \"predicted_tags\": predicted_tags,\n",
        "                \"ner_results\": {\n",
        "                    \"event_time\": ner_result[\"event_time\"],\n",
        "                    \"persons\": ner_result[\"persons\"]\n",
        "                }\n",
        "            }\n",
        "\n",
        "            # Save to database\n",
        "            record_id = self.db.save_record(record)\n",
        "\n",
        "            # Confirmation message\n",
        "            print(\"\\n--- Processing Complete ---\")\n",
        "            print(f\"Todo item saved successfully! Record ID: {record_id}\")\n",
        "            print(f\"Content: {text}\")\n",
        "            print(f\"Time: {creation_time}\")\n",
        "            print(f\"Tags: {', '.join(predicted_tags)}\")\n",
        "            self.print_separator()\n",
        "\n",
        "    def show_history(self):\n",
        "        \"\"\"Display saved records from database\"\"\"\n",
        "        records = self.db.load_records()\n",
        "\n",
        "        if not records:\n",
        "            print(\"No history records found\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\nFound {len(records)} historical records:\")\n",
        "        for record in records:\n",
        "            print(f\"\\nID: {record['id']}\")\n",
        "            print(f\"Creation Time: {record['creation_time']}\")\n",
        "            print(f\"Content: {record['original_text']}\")\n",
        "            print(f\"Predicted Tags: {', '.join(record['predicted_tags'])}\")\n",
        "\n",
        "            # Display NER results\n",
        "            ner = record['ner_results']\n",
        "            if ner['event_time']:\n",
        "                print(f\"Event Time: {ner['event_time']}\")\n",
        "            if ner['persons']:\n",
        "                print(f\"Persons: {', '.join(ner['persons'])}\")\n",
        "\n",
        "        self.print_separator()\n",
        "\n",
        "# ======================== Application Entry Point ========================\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize and run application\n",
        "    app = TodoApp()\n",
        "    app.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "3"
      ],
      "metadata": {
        "id": "APyd7ITbqSgM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "9BB8ycqOYIJG",
        "9vw_JTOSdP-p",
        "VMnBVSTXg3RL",
        "sgqJnHXJlM8g",
        "BmVWLrGnlT57"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}